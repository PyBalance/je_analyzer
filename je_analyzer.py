#!/usr/bin/env python3
"""
å‘½ä»¤è¡Œè´¢åŠ¡æ•°æ®åˆ†æåº”ç”¨ - ä¸»ç¨‹åºæ–‡ä»¶
Journal Entries Analyzer CLI Application
"""

import click
import sys
import os
import pandas as pd
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def load_data(file_path):
    """
    åŠ è½½å¹¶é¢„å¤„ç†Excelæ•°æ®

    Args:
        file_path (str): Excelæ–‡ä»¶è·¯å¾„

    Returns:
        pd.DataFrame: å¤„ç†åçš„æ•°æ®æ¡†
    """
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(file_path):
        click.echo(f"é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ - {file_path}", err=True)
        sys.exit(1)

    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    if not file_path.lower().endswith(('.xlsx', '.xls')):
        click.echo(f"é”™è¯¯ï¼šä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä½¿ç”¨Excelæ–‡ä»¶ (.xlsx æˆ– .xls) - {file_path}", err=True)
        sys.exit(1)

    try:
        # ä½¿ç”¨calamineå¼•æ“è¯»å–å¤§å‹Excelæ–‡ä»¶ï¼Œå°†æ‰€æœ‰æ•°æ®ä½œä¸ºå­—ç¬¦ä¸²ç±»å‹
        df = pd.read_excel(file_path, engine='calamine', dtype=str)

        # æ£€æŸ¥æ•°æ®æ˜¯å¦ä¸ºç©º
        if df.empty:
            click.echo(f"é”™è¯¯ï¼šExcelæ–‡ä»¶ä¸ºç©º - {file_path}", err=True)
            sys.exit(1)

        # æ¸…ç†åˆ—åï¼Œå»é™¤é¦–å°¾ç©ºæ ¼
        df.columns = df.columns.str.strip()

        # æ£€æŸ¥å¿…éœ€åˆ—
        required_columns = ['ç§‘ç›®ç¼–ç ', 'æ—¥æœŸ', 'è´¦å¥—åç§°']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            click.echo(f"é”™è¯¯ï¼šExcelæ–‡ä»¶ç¼ºå°‘å¿…éœ€åˆ— - {', '.join(missing_columns)}", err=True)
            click.echo(f"å¯ç”¨åˆ—ï¼š{', '.join(df.columns.tolist())}", err=True)
            sys.exit(1)

        # è¿›è¡Œç‰¹å®šçš„ç±»å‹è½¬æ¢
        conversion_errors = []

        if 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'], errors='coerce')
            invalid_dates = df['æ—¥æœŸ'].isna().sum()
            if invalid_dates > 0:
                conversion_errors.append(f"æ—¥æœŸåˆ—æœ‰ {invalid_dates:,} ä¸ªæ— æ•ˆæ—¥æœŸå€¼")

        if 'å€Ÿæ–¹é‡‘é¢' in df.columns:
            df['å€Ÿæ–¹é‡‘é¢'] = pd.to_numeric(df['å€Ÿæ–¹é‡‘é¢'], errors='coerce')
            invalid_debits = df['å€Ÿæ–¹é‡‘é¢'].isna().sum()
            if invalid_debits > 0:
                conversion_errors.append(f"å€Ÿæ–¹é‡‘é¢åˆ—æœ‰ {invalid_debits:,} ä¸ªæ— æ•ˆæ•°å€¼")

        if 'è´·æ–¹é‡‘é¢' in df.columns:
            df['è´·æ–¹é‡‘é¢'] = pd.to_numeric(df['è´·æ–¹é‡‘é¢'], errors='coerce')
            invalid_credits = df['è´·æ–¹é‡‘é¢'].isna().sum()
            if invalid_credits > 0:
                conversion_errors.append(f"è´·æ–¹é‡‘é¢åˆ—æœ‰ {invalid_credits:,} ä¸ªæ— æ•ˆæ•°å€¼")

        if 'å€Ÿæ­£è´·è´Ÿ' in df.columns:
            df['å€Ÿæ­£è´·è´Ÿ'] = pd.to_numeric(df['å€Ÿæ­£è´·è´Ÿ'], errors='coerce')

        # è¾“å‡ºè½¬æ¢è­¦å‘Š
        if conversion_errors:
            click.echo("è­¦å‘Šï¼šæ•°æ®ç±»å‹è½¬æ¢å‘ç°é—®é¢˜", err=True)
            for error in conversion_errors:
                click.echo(f"   - {error}", err=True)

        click.echo(f"æˆåŠŸåŠ è½½æ–‡ä»¶ï¼š{file_path} ({len(df):,} æ¡è®°å½•)", err=True)
        return df

    except FileNotFoundError:
        click.echo(f"é”™è¯¯ï¼šæ–‡ä»¶æœªæ‰¾åˆ° - {file_path}", err=True)
        sys.exit(1)
    except PermissionError:
        click.echo(f"é”™è¯¯ï¼šæ²¡æœ‰æƒé™è¯»å–æ–‡ä»¶ - {file_path}", err=True)
        sys.exit(1)
    except ValueError as e:
        click.echo(f"é”™è¯¯ï¼šæ–‡ä»¶æ ¼å¼é”™è¯¯ - {e}", err=True)
        sys.exit(1)
    except Exception as e:
        click.echo(f"é”™è¯¯ï¼šè¯»å–æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ - {file_path}", err=True)
        click.echo(f"è¯¦ç»†ä¿¡æ¯ï¼š{e}", err=True)
        sys.exit(1)


def filter_data(df, account_code, start_date, end_date, account_book, exact_match=False):
    """
    åŸºç¡€æ•°æ®ç­›é€‰

    Args:
        df (pd.DataFrame): åŸå§‹æ•°æ®
        account_code (str): ç§‘ç›®ç¼–ç 
        start_date (str): å¼€å§‹æ—¥æœŸ
        end_date (str): ç»“æŸæ—¥æœŸ
        account_book (str): è´¦å¥—åç§°
        exact_match (bool): æ˜¯å¦ä½¿ç”¨ç²¾ç¡®åŒ¹é…

    Returns:
        pd.DataFrame: ç­›é€‰åçš„æ•°æ®
    """
    try:
        # éªŒè¯è¾“å…¥å‚æ•°
        if not account_code or not account_code.strip():
            click.echo("é”™è¯¯ï¼šç§‘ç›®ç¼–ç ä¸èƒ½ä¸ºç©º", err=True)
            sys.exit(1)

        if not start_date or not end_date:
            click.echo("é”™è¯¯ï¼šå¼€å§‹æ—¥æœŸå’Œç»“æŸæ—¥æœŸä¸èƒ½ä¸ºç©º", err=True)
            sys.exit(1)

        if not account_book or not account_book.strip():
            click.echo("é”™è¯¯ï¼šè´¦å¥—åç§°ä¸èƒ½ä¸ºç©º", err=True)
            sys.exit(1)

        # è½¬æ¢æ—¥æœŸå­—ç¬¦ä¸²ä¸ºdatetimeå¯¹è±¡
        try:
            start_dt = pd.to_datetime(start_date)
            end_dt = pd.to_datetime(end_date)
        except ValueError as e:
            click.echo(f"é”™è¯¯ï¼šæ—¥æœŸæ ¼å¼æ— æ•ˆï¼Œè¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼", err=True)
            click.echo(f"å¼€å§‹æ—¥æœŸï¼š{start_date}ï¼Œç»“æŸæ—¥æœŸï¼š{end_date}", err=True)
            sys.exit(1)

        # æ£€æŸ¥æ—¥æœŸèŒƒå›´åˆç†æ€§
        if start_dt > end_dt:
            click.echo(f"é”™è¯¯ï¼šå¼€å§‹æ—¥æœŸä¸èƒ½æ™šäºç»“æŸæ—¥æœŸ", err=True)
            click.echo(f"å¼€å§‹æ—¥æœŸï¼š{start_dt.date()}ï¼Œç»“æŸæ—¥æœŸï¼š{end_dt.date()}", err=True)
            sys.exit(1)

        # ç§‘ç›®ç¼–ç ç­›é€‰
        if 'ç§‘ç›®ç¼–ç ' in df.columns:
            if exact_match:
                # ç²¾ç¡®åŒ¹é…
                filtered_df = df[df['ç§‘ç›®ç¼–ç '] == str(account_code)]
            else:
                # å‰ç¼€åŒ¹é…
                filtered_df = df[df['ç§‘ç›®ç¼–ç '].str.startswith(str(account_code))]
        else:
            click.echo("é”™è¯¯ï¼šæ•°æ®ä¸­ç¼ºå°‘'ç§‘ç›®ç¼–ç 'åˆ—", err=True)
            sys.exit(1)

        # æ—¥æœŸèŒƒå›´ç­›é€‰
        if 'æ—¥æœŸ' in filtered_df.columns:
            date_mask = (filtered_df['æ—¥æœŸ'] >= start_dt) & (filtered_df['æ—¥æœŸ'] <= end_dt)
            filtered_df = filtered_df[date_mask]
        else:
            click.echo("é”™è¯¯ï¼šæ•°æ®ä¸­ç¼ºå°‘'æ—¥æœŸ'åˆ—", err=True)
            sys.exit(1)

        # è´¦å¥—ç­›é€‰
        if 'è´¦å¥—åç§°' in filtered_df.columns:
            if account_book.lower() == 'all':
                # åŒ…å«æ‰€æœ‰è´¦å¥—
                pass
            elif ',' in account_book:
                # å¤šä¸ªè´¦å¥—
                account_books = [book.strip() for book in account_book.split(',')]
                # æ£€æŸ¥è´¦å¥—æ˜¯å¦å­˜åœ¨
                existing_books = set(filtered_df['è´¦å¥—åç§°'].unique())
                invalid_books = [book for book in account_books if book not in existing_books]
                if invalid_books:
                    click.echo(f"è­¦å‘Šï¼šä»¥ä¸‹è´¦å¥—ä¸å­˜åœ¨äºæ•°æ®ä¸­ï¼š{', '.join(invalid_books)}", err=True)
                    click.echo(f"å¯ç”¨è´¦å¥—ï¼š{', '.join(sorted(existing_books))}", err=True)
                filtered_df = filtered_df[filtered_df['è´¦å¥—åç§°'].isin(account_books)]
            else:
                # å•ä¸ªè´¦å¥—
                if account_book not in filtered_df['è´¦å¥—åç§°'].unique():
                    click.echo(f"è­¦å‘Šï¼šè´¦å¥— '{account_book}' ä¸å­˜åœ¨äºæ•°æ®ä¸­", err=True)
                    click.echo(f"å¯ç”¨è´¦å¥—ï¼š{', '.join(sorted(filtered_df['è´¦å¥—åç§°'].unique()))}", err=True)
                filtered_df = filtered_df[filtered_df['è´¦å¥—åç§°'] == account_book]
        else:
            click.echo("é”™è¯¯ï¼šæ•°æ®ä¸­ç¼ºå°‘'è´¦å¥—åç§°'åˆ—", err=True)
            sys.exit(1)

        return filtered_df

    except Exception as e:
        click.echo(f"é”™è¯¯ï¼šæ•°æ®ç­›é€‰è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ - {e}", err=True)
        sys.exit(1)


def apply_top_n_filter(df, top_n, top_type):
    """
    åº”ç”¨Top Nç­›é€‰ï¼ŒæŒ‰æŒ‡å®šæ¡ä»¶æ’åºå¹¶è¿”å›å‰Næ¡è®°å½•

    Args:
        df (pd.DataFrame): ç­›é€‰åçš„æ•°æ®
        top_n (int): è¿”å›çš„è®°å½•æ•°ï¼Œå¦‚æœä¸ºNoneæˆ–<=0åˆ™è¿”å›æ‰€æœ‰è®°å½•
        top_type (str): æ’åºä¾æ®ï¼Œå¯é€‰å€¼:
            - 'debit': æŒ‰å€Ÿæ–¹é‡‘é¢é™åºæ’åº
            - 'credit': æŒ‰è´·æ–¹é‡‘é¢é™åºæ’åº
            - 'both': æŒ‰å€Ÿæ–¹æˆ–è´·æ–¹é‡‘é¢çš„ç»å¯¹å€¼æœ€å¤§å€¼æ’åº

    Returns:
        pd.DataFrame: æ’åºåçš„å‰Næ¡è®°å½•ï¼Œæˆ–åŸå§‹æ•°æ®æ¡†ï¼ˆå¦‚æœtop_næ— æ•ˆï¼‰

    æ³¨æ„:
        å¦‚æœæŒ‡å®šçš„æ’åºåˆ—ä¸å­˜åœ¨ï¼Œä¼šå°è¯•ä½¿ç”¨å…¶ä»–å¯ç”¨çš„é‡‘é¢åˆ—
    """
    if top_n is None or top_n <= 0:
        return df

    if len(df) == 0:
        return df

    # å¤åˆ¶æ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
    result_df = df.copy()

    if top_type == 'debit':
        # æŒ‰å€Ÿæ–¹é‡‘é¢é™åºæ’åº
        if 'å€Ÿæ–¹é‡‘é¢' in result_df.columns:
            result_df = result_df.sort_values('å€Ÿæ–¹é‡‘é¢', ascending=False)
    elif top_type == 'credit':
        # æŒ‰è´·æ–¹é‡‘é¢é™åºæ’åº
        if 'è´·æ–¹é‡‘é¢' in result_df.columns:
            result_df = result_df.sort_values('è´·æ–¹é‡‘é¢', ascending=False)
    elif top_type == 'both':
        # æŒ‰å€Ÿæ–¹æˆ–è´·æ–¹é‡‘é¢çš„ç»å¯¹å€¼æœ€å¤§å€¼æ’åº
        if 'å€Ÿæ–¹é‡‘é¢' in result_df.columns and 'è´·æ–¹é‡‘é¢' in result_df.columns:
            result_df['max_amount'] = result_df[['å€Ÿæ–¹é‡‘é¢', 'è´·æ–¹é‡‘é¢']].abs().max(axis=1)
            result_df = result_df.sort_values('max_amount', ascending=False)
            result_df = result_df.drop(columns=['max_amount'])
        elif 'å€Ÿæ–¹é‡‘é¢' in result_df.columns:
            result_df = result_df.sort_values('å€Ÿæ–¹é‡‘é¢', ascending=False)
        elif 'è´·æ–¹é‡‘é¢' in result_df.columns:
            result_df = result_df.sort_values('è´·æ–¹é‡‘é¢', ascending=False)

    # è¿”å›å‰Næ¡è®°å½•
    return result_df.head(top_n)


def select_columns(df, columns_config):
    """
    æ ¹æ®é…ç½®é€‰æ‹©è¾“å‡ºåˆ—ï¼Œæ”¯æŒå¤šç§æ¨¡å¼

    Args:
        df (pd.DataFrame): è¾“å…¥æ•°æ®
        columns_config (str): åˆ—é…ç½®æ¨¡å¼ï¼Œæ”¯æŒ:
            - 'all': è¿”å›æ•°æ®æ¡†ä¸­çš„æ‰€æœ‰åˆ—
            - 'default': è¿”å›é¢„è®¾çš„å¸¸ç”¨åˆ—ï¼Œè‡ªåŠ¨ç§»é™¤å…¨ç©ºçš„åˆ—
            - é€—å·åˆ†éš”çš„åˆ—å: è‡ªå®šä¹‰åˆ—é€‰æ‹©ï¼ˆå¦‚ï¼š"æ—¥æœŸ,æ‘˜è¦,å€Ÿæ–¹é‡‘é¢"ï¼‰

    Returns:
        pd.DataFrame: åŒ…å«é€‰å®šåˆ—çš„æ•°æ®æ¡†

    ç‰¹æ®Šé€»è¾‘:
        â€¢ defaultæ¨¡å¼ä¼šè‡ªåŠ¨æ£€æŸ¥å®¢æˆ·åç§°ã€ä¾›åº”å•†åç§°ã€é¡¹ç›®åç§°ä¸‰åˆ—
        â€¢ å¦‚æœè¿™äº›åˆ—çš„æ‰€æœ‰å€¼éƒ½ä¸ºç©ºï¼Œåˆ™ä¼šä»è¾“å‡ºä¸­ç§»é™¤
        â€¢ è‡ªå®šä¹‰åˆ—æ¨¡å¼ä¸‹ä¼šæ˜¾ç¤ºè­¦å‘Šå“ªäº›åˆ—ä¸å­˜åœ¨
    """
    if columns_config == 'all':
        # è¿”å›æ‰€æœ‰åˆ—
        return df

    elif columns_config == 'default':
        # é»˜è®¤åˆ—
        default_columns = [
            'è´¦å¥—åç§°', 'ç§‘ç›®ç¼–ç ', 'ç§‘ç›®å…¨ç§°', 'æ‘˜è¦',
            'å‡­è¯å”¯ä¸€å·', 'å‡­è¯è¡Œå·', 'å€Ÿæ–¹é‡‘é¢', 'è´·æ–¹é‡‘é¢',
            'æ—¥æœŸ', 'å®¢æˆ·åç§°', 'ä¾›åº”å•†åç§°', 'é¡¹ç›®åç§°'
        ]

        # é€‰æ‹©å­˜åœ¨çš„åˆ—
        available_columns = [col for col in default_columns if col in df.columns]

        # ç‰¹æ®Šé€»è¾‘ï¼šæ£€æŸ¥å®¢æˆ·åç§°ã€ä¾›åº”å•†åç§°ã€é¡¹ç›®åç§°æ˜¯å¦å…¨ä¸ºç©º
        columns_to_remove = []
        for col in ['å®¢æˆ·åç§°', 'ä¾›åº”å•†åç§°', 'é¡¹ç›®åç§°']:
            if col in available_columns and df[col].isnull().all():
                columns_to_remove.append(col)

        final_columns = [col for col in available_columns if col not in columns_to_remove]
        return df[final_columns]

    else:
        # è‡ªå®šä¹‰åˆ—ï¼ˆé€—å·åˆ†éš”ï¼‰
        custom_columns = [col.strip() for col in columns_config.split(',')]
        available_columns = [col for col in custom_columns if col in df.columns]
        missing_columns = set(custom_columns) - set(available_columns)

        if missing_columns:
            click.echo(f"è­¦å‘Šï¼šä»¥ä¸‹åˆ—ä¸å­˜åœ¨äºæ•°æ®ä¸­ï¼š{', '.join(missing_columns)}", err=True)

        return df[available_columns] if available_columns else df


def calculate_statistics(df):
    """
    è®¡ç®—åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯

    Args:
        df (pd.DataFrame): æ•°æ®

    Returns:
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'total_records': len(df),
        'debit_distribution': {},
        'credit_distribution': {}
    }

    # è®¡ç®—å€Ÿæ–¹é‡‘é¢åˆ†å¸ƒ
    if 'å€Ÿæ–¹é‡‘é¢' in df.columns:
        debit_data = df['å€Ÿæ–¹é‡‘é¢'].dropna()
        if len(debit_data) > 0:
            stats['debit_distribution'] = {
                'average': debit_data.mean(),
                'mode': debit_data.mode().iloc[0] if not debit_data.mode().empty else None,
                'mode_frequency': debit_data.value_counts().iloc[0] if not debit_data.value_counts().empty else 0
            }

    # è®¡ç®—è´·æ–¹é‡‘é¢åˆ†å¸ƒ
    if 'è´·æ–¹é‡‘é¢' in df.columns:
        credit_data = df['è´·æ–¹é‡‘é¢'].dropna()
        if len(credit_data) > 0:
            stats['credit_distribution'] = {
                'average': credit_data.mean(),
                'mode': credit_data.mode().iloc[0] if not credit_data.mode().empty else None,
                'mode_frequency': credit_data.value_counts().iloc[0] if not credit_data.value_counts().empty else 0
            }

    return stats


def analyze_summary_word_frequency(df, top_n=10):
    """
    åˆ†ææ‘˜è¦åˆ—è¯é¢‘

    Args:
        df (pd.DataFrame): æ•°æ®
        top_n (int): è¿”å›å‰Nä¸ªé«˜é¢‘è¯

    Returns:
        list: é«˜é¢‘è¯åˆ—è¡¨ [(word, count), ...]
    """
    if 'æ‘˜è¦' not in df.columns:
        return []

    # ä½¿ç”¨ç®€å•çš„åˆ†è¯æ–¹æ¡ˆ
    click.echo("æç¤ºï¼šä½¿ç”¨ç®€å•åˆ†è¯è¿›è¡Œè¯é¢‘åˆ†æ", err=True)
    return simple_word_frequency(df, top_n)


def simple_word_frequency(df, top_n=10):
    """
    ç®€å•çš„è¯é¢‘åˆ†æï¼ˆä¸ä½¿ç”¨cutwordï¼‰

    Args:
        df (pd.DataFrame): æ•°æ®
        top_n (int): è¿”å›å‰Nä¸ªé«˜é¢‘è¯

    Returns:
        list: é«˜é¢‘è¯åˆ—è¡¨ [(word, count), ...]
    """
    import re

    # åˆå¹¶æ‰€æœ‰æ‘˜è¦æ–‡æœ¬
    all_text = ' '.join(df['æ‘˜è¦'].fillna('').astype(str))

    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿›è¡Œç®€å•çš„ä¸­æ–‡åˆ†è¯
    # åŒ¹é…ä¸­æ–‡å­—ç¬¦ã€æ•°å­—å’Œå¸¸è§è¯æ±‡
    words = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z0-9]+', all_text)

    # è¿‡æ»¤å¸¸è§æ— æ„ä¹‰è¯æ±‡
    stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™', 'é‚£', 'ç°åœ¨', 'å¯ä»¥', 'ä½†æ˜¯', 'è¿˜æ˜¯', 'å› ä¸º', 'ä»€ä¹ˆ', 'å¦‚æœ', 'æ‰€ä»¥', 'å¯¹äº', 'å…³äº', 'æ ¹æ®', 'é€šè¿‡', 'è¿›è¡Œ', 'å®ç°', 'å®Œæˆ', 'å·¥ä½œ', 'é¡¹ç›®', 'æŠ€æœ¯', 'å¼€å‘', 'è®¾è®¡', 'ç³»ç»Ÿ', 'ç®¡ç†', 'æœåŠ¡', 'äº§å“', 'ä¸šåŠ¡', 'å¸‚åœº', 'å®¢æˆ·', 'ç”¨æˆ·', 'å…¬å¸', 'ä¼ä¸š', 'éƒ¨é—¨', 'å›¢é˜Ÿ', 'äººå‘˜', 'æ—¶é—´', 'è´¹ç”¨', 'æˆæœ¬', 'ä»·æ ¼', 'æ”¶å…¥', 'æ”¯å‡º', 'èµ„é‡‘', 'é“¶è¡Œ', 'è½¬è´¦', 'æ”¶æ¬¾', 'ä»˜æ¬¾'}

    # ç»Ÿè®¡è¯é¢‘
    word_freq = {}
    for word in words:
        if len(word.strip()) > 1 and word.strip() not in stop_words:
            word_freq[word] = word_freq.get(word, 0) + 1

    # è¿”å›å‰Nä¸ªé«˜é¢‘è¯
    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
    return sorted_words[:top_n]


def format_overview_report(stats, word_freq):
    """
    æ ¼å¼åŒ–æ¦‚è§ˆæŠ¥å‘Š

    Args:
        stats (dict): ç»Ÿè®¡ä¿¡æ¯
        word_freq (list): è¯é¢‘åˆ—è¡¨

    Returns:
        str: æ ¼å¼åŒ–çš„æŠ¥å‘Š
    """
    report = []

    # åŸºæœ¬ç»Ÿè®¡
    report.append("=" * 60)
    report.append("è´¢åŠ¡æ•°æ®åˆ†ææ¦‚è§ˆæŠ¥å‘Š")
    report.append("=" * 60)
    report.append("")

    # æ€»è®°å½•æ•°
    report.append(f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡")
    report.append(f"   æ€»è®°å½•æ•°: {stats['total_records']:,}")
    report.append("")

    # å€Ÿæ–¹é‡‘é¢åˆ†å¸ƒ
    if stats['debit_distribution']:
        report.append(f"ğŸ’° å€Ÿæ–¹é‡‘é¢åˆ†å¸ƒ")
        report.append(f"   å¹³å‡å€¼: {stats['debit_distribution']['average']:,.2f}")
        if stats['debit_distribution']['mode'] is not None:
            report.append(f"   ä¼—æ•°: {stats['debit_distribution']['mode']:,.2f}")
            report.append(f"   ä¼—æ•°é¢‘ç‡: {stats['debit_distribution']['mode_frequency']:,}")
        report.append("")

    # è´·æ–¹é‡‘é¢åˆ†å¸ƒ
    if stats['credit_distribution']:
        report.append(f"ğŸ’³ è´·æ–¹é‡‘é¢åˆ†å¸ƒ")
        report.append(f"   å¹³å‡å€¼: {stats['credit_distribution']['average']:,.2f}")
        if stats['credit_distribution']['mode'] is not None:
            report.append(f"   ä¼—æ•°: {stats['credit_distribution']['mode']:,.2f}")
            report.append(f"   ä¼—æ•°é¢‘ç‡: {stats['credit_distribution']['mode_frequency']:,}")
        report.append("")

    # æ‘˜è¦è¯é¢‘åˆ†æ
    if word_freq:
        report.append(f"ğŸ“ æ‘˜è¦è¯é¢‘åˆ†æ (Top {len(word_freq)})")
        for i, (word, count) in enumerate(word_freq, 1):
            report.append(f"   {i:2d}. {word}: {count:,}")
        report.append("")

    report.append("=" * 60)

    return "\n".join(report)


@click.group()
@click.argument('input_file', type=click.Path(exists=True))
@click.option('-a', '--account-code', required=True,
              help='ä¼šè®¡ç§‘ç›®ç¼–ç  (ä¾‹å¦‚: 1002, 6601.01)')
@click.option('--exact-match', is_flag=True,
              help='ä½¿ç”¨ç²¾ç¡®åŒ¹é…ç§‘ç›®ç¼–ç  (é»˜è®¤ä¸ºå‰ç¼€åŒ¹é…)')
@click.option('-s', '--start-date', required=True,
              help='åˆ†ææœŸé—´å¼€å§‹æ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)')
@click.option('-e', '--end-date', required=True,
              help='åˆ†ææœŸé—´ç»“æŸæ—¥æœŸ (æ ¼å¼: YYYY-MM-DD)')
@click.option('-b', '--account-book', required=True,
              help='è´¦å¥—åç§° (æ”¯æŒ: "è´¦å¥—A", "è´¦å¥—A,è´¦å¥—B", "all")')
@click.option('-q', '--query',
              help='PandasæŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œç”¨äºé¢å¤–ç­›é€‰ (ä¾‹å¦‚: "å€Ÿæ–¹é‡‘é¢ > 10000")')
@click.pass_context
def cli(ctx, input_file, account_code, exact_match, start_date, end_date, account_book, query):
    """
    è´¢åŠ¡æ•°æ®åˆ†æå‘½ä»¤è¡Œå·¥å…· (Journal Entries Analyzer)

    å¿«é€Ÿåˆ†æå’Œç­›é€‰è´¢åŠ¡æ—¥è®°è´¦æ•°æ®ï¼Œæ”¯æŒå¤šç§ç­›é€‰æ¡ä»¶å’Œç»Ÿè®¡åˆ†æã€‚

    ä½¿ç”¨ç¤ºä¾‹:
      uv run python je_analyzer.py data.xlsx overview -a 1002 -s 2024-01-01 -e 2024-12-31 -b "ä¸»è´¦å¥—"
      uv run python je_analyzer.py data.xlsx get --top 10 -a 6601 -s 2024-01-01 -e 2024-12-31 -b "ä¸»è´¦å¥—"

    INPUT_FILE: åŒ…å«ä¼šè®¡åˆ†å½•æ•°æ®çš„æºæ–‡ä»¶è·¯å¾„ (.xlsx æˆ– .xls)
    """
    ctx.ensure_object(dict)
    ctx.obj['input_file'] = input_file
    ctx.obj['account_code'] = account_code
    ctx.obj['exact_match'] = exact_match
    ctx.obj['start_date'] = start_date
    ctx.obj['end_date'] = end_date
    ctx.obj['account_book'] = account_book
    ctx.obj['query'] = query


@cli.command()
@click.pass_context
def overview(ctx):
    """
    ç”Ÿæˆè´¢åŠ¡æ•°æ®åˆ†ææ¦‚è§ˆæŠ¥å‘Š

    è¾“å‡ºåŒ…å«ä»¥ä¸‹å†…å®¹çš„ç»Ÿè®¡æŠ¥å‘Š:
    â€¢ åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯ (æ€»è®°å½•æ•°)
    â€¢ å€Ÿæ–¹é‡‘é¢åˆ†å¸ƒ (å¹³å‡å€¼ã€ä¼—æ•°ã€ä¼—æ•°é¢‘ç‡)
    â€¢ è´·æ–¹é‡‘é¢åˆ†å¸ƒ (å¹³å‡å€¼ã€ä¼—æ•°ã€ä¼—æ•°é¢‘ç‡)
    â€¢ æ‘˜è¦è¯é¢‘åˆ†æ (é«˜é¢‘è¯æ±‡ç»Ÿè®¡)

    ç¤ºä¾‹:
      je_analyzer.py data.xlsx overview -a 1002 -s 2024-01-01 -e 2024-12-31 -b "ä¸»è´¦å¥—"
    """
    # åŠ è½½æ•°æ®
    df = load_data(ctx.obj['input_file'])

    # åŸºç¡€ç­›é€‰
    filtered_df = filter_data(
        df,
        ctx.obj['account_code'],
        ctx.obj['start_date'],
        ctx.obj['end_date'],
        ctx.obj['account_book'],
        ctx.obj['exact_match']
    )

    # é«˜çº§ç­›é€‰
    if ctx.obj['query']:
        try:
            filtered_df = filtered_df.query(ctx.obj['query'])
        except Exception as e:
            click.echo(f"é”™è¯¯ï¼šæŸ¥è¯¢è¯­æ³•é”™è¯¯ - {e}", err=True)
            sys.exit(1)

    if len(filtered_df) == 0:
        click.echo("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®°å½•", err=True)
        return

    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    stats = calculate_statistics(filtered_df)

    # åˆ†ææ‘˜è¦è¯é¢‘
    word_freq = analyze_summary_word_frequency(filtered_df)

    # ç”Ÿæˆå¹¶è¾“å‡ºæŠ¥å‘Š
    report = format_overview_report(stats, word_freq)
    click.echo(report)


@cli.command()
@click.option('--top', type=int, help='è¿”å›Top Næ¡è®°å½• (æŒ‰é‡‘é¢æ’åº)')
@click.option('--top-type', type=click.Choice(['debit', 'credit', 'both']), default='both',
              help='Top Næ’åºä¾æ®: debit=å€Ÿæ–¹é‡‘é¢, credit=è´·æ–¹é‡‘é¢, both=æœ€å¤§é‡‘é¢')
@click.option('--columns', default='default',
              help='è¾“å‡ºåˆ—æ§åˆ¶: all=æ‰€æœ‰åˆ—, default=é¢„è®¾åˆ—, "col1,col2"=è‡ªå®šä¹‰åˆ—')
@click.pass_context
def get(ctx, top, top_type, columns):
    """
    è·å–å¹¶è¾“å‡ºç­›é€‰åçš„åŸå§‹æ•°æ®è¡Œ

    è¾“å‡ºæ ¼å¼ä¸ºåˆ¶è¡¨ç¬¦åˆ†éš”ï¼Œä¾¿äºå¤åˆ¶åˆ°å…¶ä»–ç¨‹åºæˆ–è¿›ä¸€æ­¥å¤„ç†ã€‚

    åˆ—é€‰æ‹©è¯´æ˜:
    â€¢ all: è¾“å‡ºExcelæ–‡ä»¶ä¸­çš„æ‰€æœ‰åˆ—
    â€¢ default: è¾“å‡ºé¢„è®¾çš„å¸¸ç”¨åˆ— (è‡ªåŠ¨ç§»é™¤ç©ºåˆ—)
    â€¢ è‡ªå®šä¹‰: æŒ‡å®šåˆ—åï¼Œç”¨é€—å·åˆ†éš” (å¦‚: "æ—¥æœŸ,æ‘˜è¦,å€Ÿæ–¹é‡‘é¢")

    ç¤ºä¾‹:
      je_analyzer.py data.xlsx get --top 10 -a 1002 -s 2024-01-01 -e 2024-12-31 -b "ä¸»è´¦å¥—"
      je_analyzer.py data.xlsx get --top 5 --top-type debit --columns "æ—¥æœŸ,æ‘˜è¦,å€Ÿæ–¹é‡‘é¢"
    """
    # åŠ è½½æ•°æ®
    df = load_data(ctx.obj['input_file'])

    # åŸºç¡€ç­›é€‰
    filtered_df = filter_data(
        df,
        ctx.obj['account_code'],
        ctx.obj['start_date'],
        ctx.obj['end_date'],
        ctx.obj['account_book'],
        ctx.obj['exact_match']
    )

    # é«˜çº§ç­›é€‰
    if ctx.obj['query']:
        try:
            filtered_df = filtered_df.query(ctx.obj['query'])
        except Exception as e:
            click.echo(f"é”™è¯¯ï¼šæŸ¥è¯¢è¯­æ³•é”™è¯¯ - {e}", err=True)
            sys.exit(1)

    # åº”ç”¨Top Nç­›é€‰
    result_df = apply_top_n_filter(filtered_df, top, top_type)

    # é€‰æ‹©è¾“å‡ºåˆ—
    result_df = select_columns(result_df, columns)

    # è¾“å‡ºç»“æœï¼ˆåˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰
    if len(result_df) > 0:
        result_df.to_csv(sys.stdout, sep='\t', index=False, encoding='utf-8')
    else:
        click.echo("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®°å½•", err=True)


if __name__ == '__main__':
    cli()